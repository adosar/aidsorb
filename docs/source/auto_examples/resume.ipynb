{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Coming back after model training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After training a model, you might want to test its performance, make\npredictions or do whatever you want with it, such as continue training.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>This example assummes:\n        * [PyTorch Lightning checkpoints](https://lightning.ai/docs/pytorch/stable/common/checkpointing_basic.html#lightningmodule-from-checkpoint)\n          are enabled during training.\n        * Training was performed with AIdsorb :doc:`../cli` or `AIdsorb +\n          PyTorch Lightning <aidsorb_with_pytorch_and_lightning>`.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import yaml\nimport torch\nimport lightning as L\nfrom lightning.pytorch.cli import LightningCLI, LightningArgumentParser\nfrom aidsorb.datamodules import PCDDataModule\nfrom aidsorb.litmodels import PointNetLit\nfrom aidsorb.visualize import draw_pcd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following function let us recreate:\n\n* Trainer\n* LightningModule (litmodel)\n* Datamodule\n\nwith the same settings as in the ``.yaml`` configuration file. For more\ninformation \ud83d\udc49 [here](https://github.com/Lightning-AI/pytorch-lightning/discussions/10363#discussioncomment-2326235).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def load_from_config(filename):\n    r\"\"\"\n    Load configuration, trainer, model and datamodule from a ``.yaml`` file.\n\n    .. note::\n        You are responsible for restoring the model's state (the weights of the model).\n\n    Parameters\n    ----------\n    filename: str\n        Absolute or relative path to the ``.yaml`` configuration file.\n    \"\"\"\n    with open(filename, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    config_dict['trainer']['logger'] = False\n    del config_dict['seed_everything'], config_dict['ckpt_path']\n\n    parser = LightningArgumentParser()\n    parser.add_class_arguments(PointNetLit, 'model', fail_untyped=False)\n    parser.add_class_arguments(PCDDataModule, 'data', fail_untyped=False)\n    parser.add_class_arguments(L.Trainer, 'trainer', fail_untyped=False)\n    config = parser.parse_object(config_dict)\n    objects = parser.instantiate_classes(config)\n\n    return config, objects.trainer, objects.model, objects.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "config, trainer, litmodel, dm = load_from_config('path/to/logs/config.yaml')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Restoring model's state \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ckpt = torch.load('path/to/checkpoints/checkpoint.ckpt')\nmodel_weights = {k: v for k, v in ckpt['state_dict'].items() if k.startswith('model.')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Due to lazy initialization we need to pass a dummy input with correct shape.\nin_channels = 5  # For xyz + Z + 1 additional feature.\nx = torch.randn(32, in_channels, 100)\nlitmodel(x);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load back the weights.\nlitmodel.load_state_dict(model_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set the model in inference mode.\nlitmodel.eval()\nlitmodel.training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measure performance and make predictions\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Measure performance on test set.\ntrainer.test(litmodel, dm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Predict on the test set.\ny_pred = torch.cat(trainer.predict(litmodel, dm.test_dataloader()))\n\n# Predict on the train set.\ny_pred = torch.cat(trainer.predict(litmodel, dm.train_dataloader()))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}