{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb0e0e4b-4f0c-4092-b5a4-93bcc7d51e71",
   "metadata": {},
   "source": [
    "# Coming back after model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2290eda-bac5-4c35-bfcb-a05b5bbfe9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "from lightning.pytorch.cli import LightningCLI, LightningArgumentParser\n",
    "import lightning as L\n",
    "from aidsorb.datamodules import PCDDataModule\n",
    "from aidsorb.litmodels import PointNetLit\n",
    "from aidsorb.visualize import draw_pcd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dde69d2-c1c9-4f0d-b69a-c58ff4c7a5d4",
   "metadata": {},
   "source": [
    "The following function let us recreate:\n",
    "\n",
    "* Trainer\n",
    "* LightningModule (litmodel)\n",
    "* Datamodule\n",
    "\n",
    "with the same settings as in the ``.yaml`` configuration file. For more information, see [here](https://github.com/Lightning-AI/pytorch-lightning/discussions/10363#discussioncomment-2326235).\n",
    "\n",
    "The remaining step, is to load back the (trained) weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c28dd10-cc41-41ef-8839-488c98d923bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_config(filename):\n",
    "    r\"\"\"\n",
    "    Load configuration, trainer, model and datamodule from a ``.yaml`` file.\n",
    "\n",
    "    .. note::\n",
    "        1. This function assumes that all we need is to perform inference.\n",
    "        2. You are responsible for restoring the model's state (the weights of the model).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: str\n",
    "        Absolute or relative path to the ``.yaml`` configuration file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        config_dict = yaml.safe_load(f)\n",
    "\n",
    "    config_dict['trainer']['logger'] = False\n",
    "    del config_dict['seed_everything'], config_dict['ckpt_path']\n",
    "\n",
    "    parser = LightningArgumentParser()\n",
    "    parser.add_class_arguments(PointNetLit, 'model', fail_untyped=False)\n",
    "    parser.add_class_arguments(PCDDataModule, 'data', fail_untyped=False)\n",
    "    parser.add_class_arguments(L.Trainer, 'trainer', fail_untyped=False)\n",
    "    config = parser.parse_object(config_dict)\n",
    "    objects = parser.instantiate_classes(config)\n",
    "\n",
    "    return config, objects.trainer, objects.model, objects.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07fbf0e8-b7f2-4a5c-a1e8-6700b1b61d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "config, trainer, litmodel, dm = load_from_config('lightning_logs/version_0/config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06da73d-d678-4fe4-a325-78149b25cc8b",
   "metadata": {},
   "source": [
    "## Restoring model's state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ac1c21-350b-4a16-a858-9db2a4ffea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load('lightning_logs/version_0/checkpoints/best.ckpt')\n",
    "model_weights = {k: v for k, v in ckpt['state_dict'].items() if k.startswith('model.')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28305386-db4a-4804-bbca-82873eebe6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Due to lazy initialization we need to pass a dummy input with correct number of channels.\n",
    "in_channels = 7  # xyz + Z + 3 feats.\n",
    "x = torch.randn(32, in_channels, 100)\n",
    "litmodel(x);\n",
    "\n",
    "# Load back the weights.\n",
    "litmodel.load_state_dict(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea1eff5-9267-462f-a403-2529e4a0f5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model in inference mode.\n",
    "litmodel.eval()\n",
    "litmodel.training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e375e-a4aa-4e95-89b8-bb87257fa16d",
   "metadata": {},
   "source": [
    "## Measure performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6edc45e9-c731-496c-876c-871790419f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8edfb5d7814a189e505c6e5955efd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                              | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            mae            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0951441079378128     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            mse            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.028326408937573433    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         r2_score          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8966765999794006     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m           mae           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0951441079378128    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m           mse           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.028326408937573433   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        r2_score         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8966765999794006    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'r2_score': 0.8966765999794006,\n",
       "  'mae': 0.0951441079378128,\n",
       "  'mse': 0.028326408937573433}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(litmodel, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355b543e-76f0-4598-a3aa-6252cb724e59",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da2ef999-60db-436d-ab59-1fcb92fd76bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96906543f6bb4869b13b36939fca3657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                           | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = torch.cat(trainer.predict(litmodel, dm.test_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b35ec66e-071e-4a90-a7c1-214676382c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24331, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
