seed_everything: 1  # Workers are seeded as well.

# Here you setup the Trainer.
trainer:
  max_epochs: 2
  accelerator: 'gpu'

# Here you setup the DataModule (PCDDataModule).
# For more information ðŸ‘‰ aidsorb.datamodules
data:
  # The paths must be relative to where aidsorb-lit is called.
  # Consider using absolute paths.
  path_to_X: 'path/to/pcds/pcds.npz'
  path_to_Y: 'path/to/labels.csv'
  index_col: 'id'
  labels: ['y1, y3']
  train_transform_x:
    # Here you can pass transformations for augmentation.
    class_path: aidsorb.transforms.Center
  eval_transform_x:
    class_path: aidsorb.transforms.Center
  train_size: Null  # Use all training data.
  train_batch_size: 2
  eval_batch_size: 2
  shuffle: True
  config_dataloaders:
    collate_fn:
      class_path: aidsorb.data.Collator

# Here you setup the LightningModule (PointLit).
# For more information ðŸ‘‰ aidsorb.litmodels
model:
  loss:
    class_path: torch.nn.MSELoss
  metric:
    class_path: torchmetrics.MetricCollection
    init_args:
      metrics:
        r2: {class_path: torchmetrics.R2Score}
        mae: {class_path: torchmetrics.MeanAbsoluteError}
  model:
    class_path: aidsorb.models.PointNet
    init_args:
      head:
        class_path: aidsorb.modules.PointNetClsHead
        init_args:
          dropout_rate: 0.7

# Here you setup the optimizer.
optimizer:
  class_path: torch.optim.SGD
  init_args:
    lr: 0.001
    momentum: 0.0

# Here you setup the learning rate scheduler.
lr_scheduler:
  class_path: torch.optim.lr_scheduler.StepLR
  init_args:
    step_size: null
    gamma: 0.1
